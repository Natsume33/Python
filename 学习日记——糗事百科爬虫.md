## 日拱一卒无有尽，功不唐捐终入海

---
**代码如下:**
```javascript
import re
from urllib.request import Request,urlopen,ProxyHandler,build_opener
import random

base_url ='https://www.qiushibaike.com/hot/page/'

headers ={
    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.62 Safari/537.36'
}

# 随机IP
ip_list =[
    '58.17.125.215:53281'
    '122.72.18.35:80'
    '139.224.80.139:3128'
    '122.72.18.34:80'
]

proxies ={
    'http:':random.choice(ip_list)
}

def down_load_qiubai_info(pageIndex):
    full_url =base_url+str(pageIndex)+'/'
    request =Request(full_url,headers =headers)
    response =urlopen(request)
    # 获取对应网页的全部内容
    code =response.read().decode()
    # print(code)
    # 正则匹配的内容 从指定的开始为止  到全部内容结束
    # 所以只需要指定开始的位置  不需要指定结束的为止
    #
    # 如果我们想要正则获取某一对标签里面的内容的时候
    # 那么需要将这对标签写完 而且在想要获取的内容
    # 上添加（） 例如：<h2>。*？</h2>

    pattern =re.compile(r'<div class="author clearfix">.*?<h2>(.*?)</h2>.*?<div class="articleGender.*?Icon">(.*?)</div>'
                        r'.*?<a.*?href="(.*?)".*?>.*?<div class="content">.*?<span>(.*?)</span>.*?<div class="stats">.*?'
                        r'<i class="number">(.*?)</i>.*?<span class="stats-comments">.*?<i class="number">(.*?)</i>',re.S)
    result =pattern.findall(code)
    
    for name,age,href,content,num,comment in result:
        name =name.strip('\n')
        age  =age.strip('\n')
        content =content.strip('\n').replace('<br/>','')
        href =href.strip('\n')
        num =num.strip('\n')
        comment =comment.strip('\n')
        print('作者是',name)
        print('年龄是',age)
        print('详情是',href)
        print('内容是',content)

        print('好笑数',num)
        print('评论数',comment)
        if  int(comment) !=0:
            get_all_comment_with(href)
        else:
            print('该内容暂无评论')
            
# 通过字符串拼接获取评论人的主页地址
def  get_all_comment_with(url):
    deatil_url ='https://www.qiushibaike.com'+url
    # print(deatil_url)
    proxy_handler = ProxyHandler(proxies)
    request =Request(deatil_url,headers=headers)
    opener =build_opener(proxy_handler)
    response = opener.open(request)
    code =response.read().decode()
    # print(code)
    
    pattern =re.compile(r'<div class="replay">.*?<a.*?href="(.*?)".*?title="(.*?)">',re.S)
    result =pattern.findall(code)
    for href,title in result:
        title =title.strip('\n')
        href  =href.strip('\n')
        print('评论人',title)
        print('网址链接',href)
    print('----------------------------------------')



down_load_qiubai_info(1)
```

 ### 爬虫升级 随机IP和User-Agent
 
 ---
 ```javascript
import random

from urllib.request import Request,urlopen,ProxyHandler,build_opener

user_agent_list=[

    'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.62 Safari/537.36',
    
    'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:61.0) Gecko/20100101 Firefox/61.0'
]
headers ={

    'User-Agent':random.choice(user_agent_list)
}

# 搜索西刺代理找免费IP
ip_list=[

    '220.249.185.178:9999',
    '124.193.85.88:8080',
    '61.135.217.7:80',
    '111.155.116.207:8123',
    '111.155.124.84:8123'
    
]
# proxies  代理
proxies ={

    'http:':random.choice(ip_list)
    
}

# 设置爬虫目标  以及 用户标识
request =Request('http://www.baidu.com',headers =headers)

# 创建IP代理对象
proxy_handler =ProxyHandler(proxies)

# urlopen不支持http高级函数，cookie,验证，代理等内容
# 如果要使用这些内容的话，需要使用bulidopener对象进行处理
opener =build_opener(proxy_handler)

response=opener.open(request)

print(response.read().decode())
 ```

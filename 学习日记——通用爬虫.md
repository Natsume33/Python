### 日拱一卒无有尽，功不唐捐终入海

---
**代码如下**
```javascript
from urllib.request import Request,urlopen
import re
import sqlite3

class DBManager(object):
    connect = sqlite3.connect('okDB')
    cursor = connect.cursor()
    # 用True和Flase表示是在字符串还是列表
    isOneInfo = True
    # dbData = None
    
    @classmethod
    def create_table(cls , info):
        # 如果是字符串 创建一个字段
        if  DBManager.isOneInfo == True :
            cls.cursor.execute('create table if not exists spiderTable(value0 text)')
            cls.connect.commit()
        else :
            sqlStr = 'create table if not exists spiderTable ('
            for index ,value in enumerate(info) :
                # 'create tabel if not exists spiderTable(value0 text ,value1 text ,value2 text)'
                sqlStr += 'value' + str(index) + ' text ,'
            sqlStr = sqlStr[0 : -1]
            sqlStr += ')'
            cls.cursor.execute(sqlStr)
            cls.connect.commit()
            
    @classmethod
    def insert_into(cls ,info):
        print('创建表')
        print(type(info))
        if DBManager.isOneInfo == True:
            cls.cursor.execute('insert into spiderTable (value0) VALUES ("{}")'.format(info))
            cls.connect.commit()

        else :
            # 多条数据也要拼接插入
            sqlStr = 'insert into spiderTable('
            key = ''
            values = 'values('
            for index ,value in enumerate(info):
                key += 'value' + str(index) + ' ,'
                values +=  '"' + info[index] + '"' + ' ,'
            key = key[0:-1]
            key += ')'
            values = values[0:-1]
            values += ')'
            sqlStr += key + values
            cls.cursor.execute(sqlStr)
            cls.connect.commit()
            
class DataManager(object):
    # 根据源码获取指定的内容
    @classmethod
    # 分离数据 根据正则找到指定的数据
    def get_info_with_code(cls , code , patternValue):
        pattern = re.compile(r'{}'.format(patternValue),re.S)
        result = pattern.findall(code)

        return result
    @classmethod
    # 去掉数据中不必要的内容
    def change_data_with(cls ,oldData):
        # 如果获取的是一条数据，那么这条数据类型是字符串，会被放入到列表中
        # 如果获取的是多条数据，那么每条数据都是元组，也会被放入到列表中
        space = re.compile(r'\s', re.S)
        element = re.compile(r'<.*?>', re.S)
        
        if type(oldData) == str:

            print(type(oldData))
            oldData = oldData.strip('\n')
            oldData = re.sub(space,'',oldData)
            oldData = re.sub(element,'',oldData)
            DBManager.isOneInfo = True
            return  oldData
        else :
            list = []
            for content in oldData :
                content = content.strip('\n')
                content = re.sub(space,'',content)
                content = re.sub(element,'',content)
                list.append(content)
                print('list')
                print(type(oldData))
            DBManager.isOneInfo = False

            return list

class Spider(object):
    def __init__(self , base_url ='', pattern=''):
        self.base_url = base_url
        self.pattern = pattern
        self.headers = {
            'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.62 Safari/537.36'
        }
        
    def load_first_url(self):
        url  = self.base_url + '1'
        request  = Request(url , headers=self.headers)
        response = urlopen(request)
        try:
            code = response.read().decode()
        except Exception as e:
            print('请求首页错误',e)
        else :
            result_list = DataManager.get_info_with_code(code ,self.pattern)
            for value in result_list:
                # 字符串
                # 列表
                print('chuanzhi ')
                print(type(value))
                newData =  DataManager.change_data_with(value)
                # 创建数据表
                DBManager.create_table(newData)
                DBManager.insert_into(newData)


spider = Spider('https://www.qiushibaike.com/hot/page/','<div class="author clearfix">.*?<h2>(.*?)</h2>.*?<div class="content">.*?<span>(.*?)</span>')
# spider = Spider('https://tieba.baidu.com/p/5424654051?pn=','<a.*?class="p_author_name.*?".*?>(.*?)</a>.*?<div.*?class="d_post_content j_d_post_content ">(.*?)</div>')
# spider = Spider('https://www.jd.com/?cu=true&utm_source=baidu-pinzhuan&utm_medium=cpc&utm_campaign=t_288551095_baidupinzhuan&utm_term=0f3d30c8dba7459bb52f2eb5eba8ac7d_0_c8935cfd982344988eb76d0972196e63','<li.*?class="fore1".*?>.*?<a.*?>(.*?)</a>')
spider.load_first_url()

```
